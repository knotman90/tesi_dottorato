\part{Attività formative e di ricerca -  \RNum{3} anno}

\section{Corsi e Seminari}
\begin{itemize}
	\item \textbf{UKMAC 2017}, \textit{UK Manycore Developer Conference}, 11 Luglio 2017, University of Warwick
\end{itemize}

\section{Didattica}
\begin{description}
\item [\textbf{Esercitatore}] del corso di\textit{ Interfacce Grafiche e Programmazione ad Eventi} del CdL in \textit{Informatica}, \textit{Dipartimento di Matematica e Informatica}, UNICAL. \textbf{Periodo}: \textit{Marzo 2017 - Settembre 2017}
\end{description}

\section{Visiting presso altre università}
\begin{description}
	\item [da Giugno 2017 a Agosto 2017] presso il \textit{Department of Computer Science, University of Warwick (UK)} sotto la supervisione del Prof. \textit{Gihan R. Mudalige}.
\end{description}


\section{Pubblicazioni}
\begin{itemize}
	\item  Donato D'Ambrosio, Alessio De Rango, Marco Oliverio, Davide Spataro,
	William Spataro, Rocco Rongo, Giuseppe Mendicino, Alfonso Senatore:
	\textbf{The Open Computing Abstraction Layer for Extended Cellular
	Automata and the Finite Di fferences Method}, accepted with revisions to
	the \textit{ISI/SCOPUS Journal of Parallel and Distributed Computing (ISSN:
	0743-7315)}.

\item Donato D'Ambrosio, Alessio De Rango, Davide Spataro, Rocco Rongo,
William Spataro: Applications of the OpenCAL scientific library in
the context of CFD: \textbf{Applications of the \texttt{OpenCAL} scientific library to debris flows}, \textit{2017 IEEE 14th
International Conference on Networking, Sensing and Control (ICNSC)}

\item A. De Rango, D. Spataro, D. D’Ambrosio, R. Rongo, W. Spataro, \textbf{Fast
Lava Risk Assessment by Multi-GPU}, accepted at the \textbf{26th Euromicro
International Conference on Parallel, and Network-Based Computing
2018}, \textit{Cambridge (UK), March 21-23, 2018}

\end{itemize}


\section{Attività di Ricerca}


Durante l’ultimo ventennio, il modo in cui le moderne applicazioni di calcolo scientifico sono progettate, scritte ed eseguite è cambiato in maniera 
radicale, specialmente in campi come la data-analitycs, la simulazione e la 
visualizzazione. Tra le ragioni principali a causa di ciò troviamo che la dimensione dei problemi che vengono studiati oggigiorno è maggiore che in 
passato (e va aumentando anche il tasso di crescita) e che la quantità di dati 
disponibili ad essere analizzati hanno aumentato lo spettro di applicazione 
del calcolo scientifico oltre quello che non era immaginabile prima (basti 
pensare ad esempio, ai dati provenienti dai sensori delle moderne smart-city). Grandi macchine parallele sono necessarie per processare le enormi 
griglie di calcolo che le applicazioni moderne di calcolo si trovano a manipolare e che sono il risultato della modellazione di complessi problemi 
reali attraverso l’utilizzo di modelli computazionali come il metodo degli elementi/volumi/differenze finiti o gli automi cellulari. Questa tipologia di 
macchine è notoriamente complessa da programmare e richiede uno sforzo 
di programmazione non indifferente affinchè ne vengano sfruttate a pieno 
le prestazioni di questi grandi cluster, specialmente dopo l’avvento di hardware eterogeneo e la GPGPU. Durante il mio III anno di dottorato mi sono 
quindi occupato principalmente di concludere, ottimizzare e testare il lavoro 
portato avanti nei due anni precedenti sulla libreria OpenCAL, che è una 
progetto open-source che fornisce un layer di astrazione ed un domain specific language per la definizione di una famiglia di modelli numerici, il loro 
deployment ed esecuzione su macchine parallele con hardware eterogeneo. 
La libreria nasconde i dettagli di basso livello come la gestione della memoria 
o il threading legati all’hardware per il quale si vuole produrre l’applicazione. 
Il risultato è che con poco sforzo (nella maggioranza dei casi una ricompilazione) il programmatore può ottenere diverse versioni della stessa modello utilizzando lo stesso codice: dalla seriale a quella che ha come target cluster 
di GPU. La libreria è stata testata su applicazioni che mostrano caratteristiche sia \textit{compute} che \textit{memory bound} e i risultati dimostrano che è in grado 
di accelerare i modelli numerici considerati in maniera efficace.

I tre benchmark sono stati adottati:
\begin{enumerate}
	\item Julia Set: \textbf{compute bound}
	\item Convolutional Filter:\textbf{memory/bandiwidth bound}
	\item sciddicaT: \textbf{memory e compute bound}
\end{enumerate} 
La sezione \ref{sec:convolutional_filters} mostra un esempio di implementazione di un semplice filtro convoluzionale (esempiodi memory bound application), \textit{Sobel}, in \texttt{OpenCAL} e i relativi risultati di performance ottenuti.

\subsection{Convolutional Filters}
\label{sec:convolutional_filters}
La convoluzione di un'immagine può essere espressa in modo generico mediante la seguente formula:
\begin{equation}
f'_{ij} = \sum_{i'=0}^n (\sum_{j'i'=0}^m f_{(i+i')(j+j')}\times d_{ij})
\label{eq:convolution}
\end{equation}
dove
\begin{itemize}
	\item $m,n$ sono le dimensioni verticali ed orizzonatali del kernel
	\item $f_{ij}$ e $f'_{ij}$ sono rispettivamente il vecchio ed il nuovo valore della cella alla posizione $(i,j)$,
	\item $d_{ij}$ è il valore del kernel alla posizione $(i,j)$ 
\end{itemize}
\begin{figure}[!htb]
	\includegraphics[width=\linewidth]{./images/sobel_example}
	
	\caption{Esempio dell'applicazione del filtro \textit{Sobel} implementato in \texttt{OpenCAL}. }
	\label{fig:sobel}
\end{figure}

Il filtro di Sobel è facilmente implementabile in \texttt{OpenCAL} seguendo gli step che seguono::
\begin{enumerate}
	\item L'immagine viene decomposta nei canali di colore rosso, verde e blu, e ognuno di esso è letto in un sottostato di tipo short.
	\item Un \textit{cluster} file viene definito il quale specifica (si veda Listato \ref{code:sobel_cluster_file}) come il dominio deve essere diviso tra le risorse computazionali a disposizione.
	\item Il codice che implementa l'applicazione di un kernel (si veda Listato \ref{code:sobel_kernel}) a un signolo punto del dominio viene specificato dal programmatore e automaticamente eseguito in parallelo su tutto il dominio. Se un device necessità di dati che sono stati assegnati ad un altro device, questi vengono automaticamente trasferiti in maniera trasparente, anche quando essi sono fisicamente installati su nodi separati (in quel caso attraverso anche una comunicazione MPI).
\end{enumerate}
\begin{figure}
	\centering
	\caption{Sobel Scaling}
	\label{fig:sobel_scaling}
	\includegraphics[width=0.6\textwidth]{../plots/sobel_scaling}
\end{figure}
\lstset{language=[OpenCL]C,frame=tb,
	caption=Cluster file utilizzato per il benchmark Sobel. L'immagine è decomposta in maniera uniforme su $3$ devices., 
	basicstyle=\footnotesize\ttfamily,
	label={code:sobel_cluster_file}
}
\begin{lstlisting}[float]
10800 21600
1
192.168.1.111 3
0 0 3600
0 1 3600
0 2 3600
\end{lstlisting}
Figure \ref{fig:sobel_scaling} mostra  come il filtro Sobel scala al crescere del numero delle GPU utilizzate (su un singolo nodo). Si noti come diversi tipi di schede (marca ed architettura) possono essere utilizzate allo stesso momento.
La libreria supporta anche architetture distributed memory e la Figura \ref{fig:sobel_2nodes_k40+980-K20+980} mostra proprio i tempi e speedups per un esecuzione su due nodi, ognuno dei quali equipaggiato con due acceleratori (per un totale di $4$). Anche se in questo caso una comunicazione via rete è necessaria, buone performance sono comunque ottenute, con un picco di $\approx 103\times$ quando $4$ devices sono utilizzati in modo concorrente.
E' stato ottenuto un miglioramento di circa $\apoprox 22 \times$ e $\approx 103 \times $ rispetto ad un esecuzione su $3$ GPU su un singolo nodo (si veda Figura \ref{fig:sobel_scaling}) e l'esecuzione \textbf{seriale} su un singolo core.
\begin{figure}[!htb]
	\minipage{1.0\textwidth}
	\begin{subfigure}{1.0\textwidth}
		\caption{Performance su $2$ nodi e $2$ GPUs: \texttt{NVIDIA K40}(\textit{node 1}) e $1$ \texttt{GTX980}(\textit{node 2}).}
		\label{fig:sobel_2nodes_k40_980}
		\includegraphics[width=1.0\textwidth]{../plots/sobel_2nodes_k40_980}
		
	\end{subfigure}        
	\endminipage \hfill
	\minipage{1.0\textwidth}
	\vspace{5mm}
	\begin{subfigure}{1.0\textwidth}
		\includegraphics[width=1.0\textwidth]{../plots/sobel_2nodes_k40+980-K20+980}
		\caption{Performance su $2$ nodi ognuno con $2$ GPUs.}
		\label{fig:sobel_2nodes_k40+980-K20+980}
	\end{subfigure}
	\endminipage\hfill
	\caption[Performance del benchmark \textit{Sobel}  su due nodi.]{Performance del filtro Sobel su due nodi interconnessi tramite rete ethernet. (a) si riferisce al caso in cui \textit{node 1} è quipaggiato con $1$ $K40$ e \textit{node 2} con una $GTX980$. (b) al caso in cui \textit{node 1} usa una $K40$ e una $GTX980$ mentre \textit{node 2} una $K20$ ed una $GTX980$. Tempi in rosso, speed-up in blue.}
	\label{fig:sobel_2nodes_performance}
\end{figure}
\begin{minipage}{1.0\textwidth}


\lstset{language=[OpenCL]C,frame=tb,
	caption=\texttt{OpenCAL} Kernel per il filtro Sobel di edge detection., 
	label={code:sobel_kernel}, 
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\color{blue}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	commentstyle=\color{green}\ttfamily,
	backgroundcolor=\color{light-gray}, 
	numbers=left,numbersep=3pt, 
	numberstyle=\tiny\ttfamily\color{gray}
	%    numberstyle=\tiny
}
\begin{lstlisting}
__kernel void sobel2D_transitionFunction(__CALCL_MODEL_2D) {
	calclThreadCheck2D();
	int i = calclGlobalRow() + borderSize;
	int j = calclGlobalColumn();
	int KX[3][3] = {{-1, 0, 1}, {-2, 0, 2}, {-1, 0, 1}};
	int KY[3][3] = {{1, 2, 1}, {0, 0, 0}, {-1, -2, -1}};
	int Gx, Gy, n, k, k1;
	Gx = Gy = n = 0;
	if (j > 0 && j < calclGetColumns() - 1)
		for (k = -1; k <= 1; k++)
			for (k1 = -1; k1 <= 1; k1++) {
				Gx += calclGet2Di(MODEL_2D, DEVICE_Q_red, i + k, j + k1) *
				KX[k + 1][k1 + 1];
				Gy += calclGet2Di(MODEL_2D, DEVICE_Q_red, i + k, j + k1) *
				KY[k + 1][k1 + 1];
			}
	const int P = sqrt(Gx * Gx + Gy * Gy);
	// set new pixel color for red channel
	calclSet2Di(MODEL_2D, DEVICE_Q_red, i, j, P);
	return;
}
\end{lstlisting}
\end{minipage}