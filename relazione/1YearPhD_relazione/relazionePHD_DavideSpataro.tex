%%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass[a4paper]{article}
\usepackage[English]{babel}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{url}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphics} 
\usepackage{tabularx}  % for 'tabularx' environment and 'X' column type
\newcolumntype{Y}{>{\RaggedRight\arraybackslash}X}
 

  \let\oldemptyset\emptyset
\let\emptyset\varnothing
\newtheorem{mydef}{Definition}

\usepackage{booktabs}  % for \toprule, \midrule, and \bottomrule macros 

\begin{document}
\title{Relazione Finale Attività Formative \\ PhD in Matematica e
Informatica (XXX ciclo)\\ Università della Calabria}
% Title

\author{Davide \textsc{Spataro}} % Author name

\date{A.A. 2014-2015} % Date for the report


\maketitle % Insert the title, author and date

\begin{center}
\begin{tabular}{l r}
Data Esame : & \date{1-Novembre-2015} \\
Supervisori: & William Spataro \\ % Partner names
& Donato D'Ambrosio \\
\end{tabular}
\end{center}


\section{Attività Formative}


\subsection{Corsi e Seminari}




	\begin{tabularx}{\textwidth}{@{} Y c c c c @{}} % use 'Y' for first column
	\toprule
	\textbf{Denominazione} & \textbf{Docente} & \textbf{Periodo}  \\
	\midrule  \midrule
	 
	 SAT-Based Problem Solving & \textit{Joao Marques-Silva} &  Febbraio, 10-12,
	 2015 \\
	 \addlinespace \midrule 
	  Mathematical consequences of the existence of very large 
infinite cardinal numbers & \textit{Joan Bagaria i Pigrau} &  Marzo, 12,
	 2015	 \\
	 \addlinespace \midrule \addlinespace The Identification and Analysis of
	 Genomic Transposable Elements & \textit{John Karro} & Giugno, 5, 2015 \\ 
	 \addlinespace \midrule Programming GPUs with CUDA & \textit{Manuel Ujaldon} &
	 Giugno, 9-11, 2015 \\ \addlinespace \midrule Descent, CG and Newton Methods
	On the Quasi-Wolfe Conditions 
	for Self-Scaling Quasi-Newton Methods  & \textit{Mehiddin Al-Baali} &  Luglio,
	1-2, 2015\\ 	 \addlinespace \midrule 
	Congestion Games   & \textit{Angelo Fanelli} &  Gennaio, 22,
	 2015 \\
	 \addlinespace \midrule 
	\bottomrule
	\end{tabularx}

\subsection{Partecipazione a  Conferenze}

\begin{itemize}
  \item PDP-2015- Parallel,Distributed and Network-based Processing - Turku,
  Finland - 3-6 Marzo 2015
\end{itemize}


\subsection{Co-supervisione Tesi}
\begin{itemize}
  \item Laurea Magistrale in Informatica - Rahmat Hidayat - \textit{Multi agent
  syetem wih multiple groups modelling od bird flocking on GPGPU}.
\end{itemize}

\subsection{Articoli e Libri Studiati}
\subsubsection{GPGPU and Fluid Simulation}
	\begin{itemize}
	  \item  Jos Stam-\textit{Flows on Surfaces of Arbitrary Topology}
	  \item Jos Stam, \textit{Stable Fluids}
	  \item Martin Guay, Fabrice Colin, Richard Egli. \textit{Simple and Fast
	  Fluids. GPU Pro, A.K. Peters,Ltd., 2011, GPU Pro, pp.433-444}
	  \item Crane, Llamas, Tariq - GPU Gems 3, Real-Time Simulation and Rendering
	  of fluids
	   \item Mark Harris - GPU Gems,  Fast Fluid Dynamics Simulation on the GPU
	   \item Ali Khajeh-Saeedand J. Blair Perot - Computational FluidDynamics
	   Simulations using Many Graphics Processors
	   \item Stephen Wolfram - Cellular Automaton Fluids1: Basic Theory - Journal
	   of Statistical Physics
	   \item S. Pratap Vanka, Aaron F. Shinn - Computational Fluid
	   Dynamics using GPU: Challenge and Opportunities - Proceedings of the ASME
	   2011 International Mechanical Engineering Congress & Exposition IMECE-2011
	   \item Pier Luca Lanzi - Accurate real-time fluid dynamics
	   usingSmoothed-Particle Hydrodynamics and CUDA
	   \item Yaroslav D. Sergeyev, Higher order numerical differentiation on the
	   Infinity Computer, Optimization Letters, pp 575-585
	   \item Yaroslav D. Sergeyev,Solving ordinary differential equations on the
	   Infinity Computerby working with infinitesimals numerically, Journal of Applied Mathematics and
	   Computation (2013)
	   \item Markus Billeter et al. Efficient Stream Compaction on Wide SIMD
	   Many-Core Architectures
	   \item D.M. Hughes, InK-Compact: In kernel Stream Compaction and Its
	   Application to Multi-kernel Data Visualization on GPGPU
\end{itemize}
\subsubsection{Linear Ranking Function}
\begin{itemize}
  \item Roberto Bagnara, Fred Mesnard - Eventual Linear Ranking Functions 
  \item Jan Leike, Matthias Heizmann - Ranking Templates for Linear Loops
  \item Jan Leike - Ranking Function Synthesis for Linear Lasso Programs
  \item Amir M. Ben-Amram - The Hardness of Finding Linear Ranking Functions for
  Lasso Programs
  \item Amir M. Ben-Amram - Mortality of Iterated Piecewise Affine Functions
  over the Integers:  Decidability and Complexity
  \item Amir M. Ben-Amram, Samir Genaim, Abu Naser Masud - On the Termination of
  Integer Loops
  \item Amir M. Ben-Amram, Samir Genaim - Ranking Functions for
  Linear-Constraint Loops
\end{itemize}

\subsubsection{Programmazione Funzionale ed Haskell}
\begin{itemize}
  \item Michael Barr, Charles Wells - Category Theory for Computing Science
  \item Benjamin C. Pierce - A taste of category theory for computer scientists
  \item Simon Marlow - Parallel and Concurrent Programming in Haskell
  \item Simon Peyton Jones, Satnam Singh - A Tutorial on Parallel and
  Concurrent Programming in Haskell - Lecture Notes from Advanced Functional Programming Summer School 2008
\end{itemize}

\section{Pubblicazioni}
 \begin{itemize}
 \item Alessio De Rango, Mauizio Macr\'i, Davide Spataro, Donato D'Ambrosio and
  William Spataro, \textbf{Efficient Lava Flows Simulations with OpenCL: A
  preliminary application for Civil Defence Purposes}, \emph{Proceedings of
  The10th International Conference on P2P, Parallel, Grid, Cloud and Internet
  Computing, November 4-6, 2015, Krakow, Poland}
  
	\item Filippone G., Spataro W., D'Ambrosio D., Spataro D., 
	Marocco D.,Trunfio G.A., \textbf{CUDA Dynamic Active Thread List Strategy 
	to Accelerate Debris Flow Simulations} \emph{Proceedings of The 2015 International Conference on Parallel, 
	Distributed and Network-Based Processing (PDP)}, Turku, Finland, pp 330-338.
	
	\item Spataro D., D'Ambrosio D., Filippone G., Spataro W., \textbf{The new
	SCIARA-fv3 numerical model and acceleration by GPGPU strategies}
	\emph{International Journal of High Performance and Applications}.
	
	\item Hidayat R., Spataro D., D’Ambrosio D., Spataro W., \textbf{GPU Ac-
celerated Modeling of Multi-Agent System with Multiple
Group for Birds Flocking}, \emph{Parallel, Distributed and Network-
Based Processing (PDP) 2016, accepted}
\item Hidayat R., Spataro D., D’Ambrosio D., Spataro W., \textbf{Massive
Parallel Modeling of Birds Flocking on Multi-Agent Sys-
tem with Multiple Group}, \emph{IEEE Computing in Science and
Engineering, Discrete Modeling and Simulation Tools, submitted}
\end{itemize}

\section{Attività Di Ricerca}
Il mio percorso di ricerca segue due filoni principali:
\subsection{Calcolo, Simulazione, Visualizzazione e Programmazione Funzionale
parallela}
 	Nel contesto del calcolo parallelo la mia attività di ricerca si occupa di
  	investigare tecniche ed algoritmi innovativi per la simulazione di fenomeno
  	naturali attraverso macchine parallele ed in particolare utilizzando la GPGPU
  	programming. Forte enfasi è data ad una classe ampia di problemi la cui
  	formulazione matematica è basata su equazioni differenziali e le cui
  	soluzioni numeriche efficienti sono ottenibili mediante decomposizioni a griglia
  	(Finite element method - \textbf{FEM} -, Finite Volume Method - \textbf{FVM}
  	-).
  	
 
  	
  	\subsection{Stream Compaction}
  	Ho studiato e sviluppato  un approccio efficiente al problema della stream compaction su processori
  	grafici di nuova generazione che hanno introdotto le primitive hardware di
  	ballotting intra-warps.
  	
  	La stream compaction/reduction è intuitivamente l'operazione di
  	rimozione, da una collezione, di elementi che non soddisfano un dato
  	criterio.
  	
  	Più nel dettaglio, data una lista di elementi  $A_0..A_{N-1}$ di $N$ elementi
  	ed un predicato $p:A \mapsto \{True,False\}$, il risultato dell'operazione di
  	stream compaction di $A$ sotto $p$ è $B=\{x \in A \;|\; p(x)=\ True\}$. 
  	Spesso, nelle applicazioni reali è sufficiente riordinare $A$ tale che gli
  	elementi validi siano raggruppati. 
  	
  	La stream compaction è parte fondamentale dell'implementazione
  	efficiente di molti algoritmi paralleli dove strutture dati sparse di grandi
  	dimensioni possono essere  difficili da processare, come ad esempio  in
  	algoritmi di parallel breadht tree traversing, ray tracing, AC, etc.,
  	e possono portare ad un degrado prestazionale in temini di tempi
  	d'esecuzione ed efficienza parallela\footnote{Definita come $E=\frac{S}{N}
  	$ con $S=\frac{T_1}{T_N}$ ed $N$ il numero di processori utilizzati.}.
  	L'implementazione seriale è banale mentre quella parallela richiede uno sforzo maggiore, specialmente su
  	architettura SIMT (single instruction multiple thread) dove è richiesto un
  	ulteriore step intermedio, la prefix sum (o scan). 
  	\begin{mydef}{Prefix Scan}
  	
  		Dato un operatore binario associativo  $\diamond$, una collezione di $N$
  		elementi $V_{0 \ldots {N-1}}$ ed un elemento identità $I$ per $\diamond$
  		allora la prefix scan è la collezione $P$ definita come segue:
  		\[
  		P= \{I,V_0,(V_0 \diamond V_1),(V_0 \diamond V_1 \diamond V_2) \ldots
  		(V_0 \diamond V_1 \diamond \ldots \diamond V_{N-1}) \}
  		\]
  		
  	\end{mydef}
  	
  	\subsubsection{Stream Compaction parallela}\
  		Supponiamo che $P$ sia il numero di processori ed $N$ la size della
  		collezione, $N>P$ (nei casi reali $N>>P$) e che l'input stream
  		sia diviso in substream di size $S$.
  		L'algoritmo è composto da tre fasi distinte:
  		\begin{enumerate}
  		  \item Ogni processore $p_i$ conta in modo indipendente il numero di
  		  elementi validi nel proprio substream salvandolo in $PC[p_i]$
  		  \item Viene effettuata un' operazione di prefix sum ($\diamond = +, I=1$)
  		  su $PC$ producendo l'offset a cui ogni processore scriverà il proprio
  		  risultato finale $PO[p_i]$.
  		  \item Ogni processore scrive in modo indipendente il proprio output (gli
  		  elementi validi) senza interferire con gli altri nella locazione
  		  $OUT[PO[p_i]]$.
  		\end{enumerate}
 
 
  \subsubsection{Stream Compaction on SIMT Hardware}\label{smparallel}
  L'hardware  delle moderne GPU è composto di un numero dell'ordine delle decine
  di streaming multiprocessors (SMM), che intuitivamente sono un array di processori SIMD a
  loro volta composti dalle SIMD lanes, i cosidetti Streaming Processors. Le
  nuove architetture hardware NVIDIA contano 16 SMM e 128 SP per SMM per un
  totale di oltre 2000 cores.
  Ogni SMM esegue il threads a blocchi indivisibili di 32, i warp, all'interno
  dei quali ogni thread esege in modo sincrono le stesse istruzioni. SMM non
  sono processori scalari e quindi usando lo stesso approccio descritto al
  paragrafo \ref{smparallel}, si otterebbero valori di efficienza parallelo
  molto bassi a causa del fatto che per ogni SMM verrebbe utilizzato un solo
  core (avremmo infatti un altissimo numero di idle SIMD
  lanes,$16\times(128−1)=2048−16$).
  
  Per ovviare a questo problema ogni fase dell'algoritmo descritto al paragrafo
  \ref{smparallel} è stata riadattata per sfruttare al massimo la potenza di
  calcolo disponibile, ed in particolare:
  \begin{description}
  \item[Phase 1]
  	Ogni SMM ha il compito di gestire una porzione dello stream di input, e
  	procedendo a gruppi di \textbf{warpSize} calcola, tramite un operazione di
  	reduce il numero di elementi validi nella
  	porzione dell'input gestita dal SMM.
  \item[Phase 2]
  	Output della fase precendente è un array di counter che viene usato durante
  	questa fase per calcolare, attraverso l'operazione di prefix sum, l'offset
  	di output per ogni SMM.
  \item[Phase 3]
  	Questa fase prende in input lo stream da compattare e l'array di offset
  	calcolato alla fase precedente e restituisce in output lo stream compattato.
  	Utilizza le funzioni di ballotting (introdotte nelle moderne architetture
  	GPU) che consentono a i thread di uno stesso warp di comunicare senza
  	incorrere in alcun overhead. Intuitivamente computa warp, block a grid
  	offset, in modo che ogni thread abbia a disposizione l'esatta locazione di
  	output per un elemento valido dello stream di input\footnote{Che ha indice
  	di output: offset del thread nel warp sommato a quello del warp nel blocco,
  	e quello del blocco nella griglia.}.
  \end{description}
  I moduli CUDA/C che implementano questa operazione sono liberamente
  disponibili al seguente url: \url{https://github.com/knotman90/cuStreamComp}
  
  \subsection{OpenCAL - Multi platform parallel CA library}
  Ho lavorato ad una libreria multi-platform per automi cellulari open source
  per la definizione ed esecuzione parallela di un ampia classe di AC. Ad oggi
  il lavoro ha portato ad avere un software che riesce ad essere eseguito su
  macchine:
  \begin{itemize}
    \item Shared memory
    \item Hybrid memory
    \item GPU NVIDIA (CUDA, OPENCL)
    \item GPU AMD (OPENCL)
  \end{itemize}
  La libreria offre un astrazione all'utente che non deve preoccuparsi  di tutta la machinery
  necessaria all'esecuzione ed ottimizzazione parallele. Assieme ad un
  astrazione logica, vengono proposte una serie di astrazioni grafiche (in
  particolare nella versione OpenCAL-GL) che permettono di ottenere
  interfacce grafice 3D modulari per la visualizzazione interattiva
  dell'esecuzione dell'automa cellulare. 
  
  \subsection{Bird Flock Simulation on GPU}
  Ho lavorato ad un simulatore parallelo su GPU per la simulazione di Bird
  flocks basato sul modello di proposto da Craig W. Reynolds in 1987. Esso
  descrive tre leggi cui ogni agente della simulazione ad ogni step
  temporale obbedisce:
  \begin{description}
    \item[1: coesione] è il vettore forza diretto verso il centro di massa dello
    stormo 
    \item [2: separazione]  è il vettore forza, che mantiene l'agente ad una
    distanza minima da tutti gli altri boids
    \item [3: allineamento] è la forza che sincronizza i vettori velocità di un
    agente con i suoi vicini
  \end{description}
  
  Il sistema, adotta un approccio multi-agents multiple
  groups per la modellazione della dinamica degli stormi. Il modello sviluppato
  è basato su quello di Reynolds, e lo estende aggiungendo il supporto alla
  coesistenza e l'interazione di diverse specie e per la presenza di predatori.
Gli esperimenti condotti mostrano che l'utilizzo della GPGPU in questo ambito ha
garantito un significativo aumento delle performance in termini di speedup
(fino a 700x) confermando la validità di questa tecnologia anche in ambito
multi-agents modeling. 

Questo lavoro ha ispirato il design di una libreria per
agenti autonomi in GPU che verrà sviluppata durante il secondo anno di PhD.
  
 	\subsection{Soluzioni numeriche di ODE e PDE utilizzando Grossone}
  	Assieme al prof. Ya. D. Sergeyev, basandoci su un suo lavoro che applica il
  	sistema numerico Grossone, da lui ideato, alla risoluzione di ODE e PDE
  	abbiamo sviluppato una libreria Haskell per la manipolazione numerica di
  	equazioni differenziali nel suddetto sistema numerico. Questa sarà uno dei
  	blocchi costituenti di un solver parallelo a precisione arbitraria.
  	

  
  \subsection{Termination problem e ranking functions}
  L'analisi della terminazione è stata oggetto di numerosi studi negli ultimi
  anni, con un conseguente aumento del numero e dell'accuratezza dei tools per
  lo studio statico della terminazione di programmi.
  
  Il caso generale, l'halting problem, è indecidibile, ma molte sottoclassi
  sono decidibili e ampiamente studiate, come ad esempio quello della
  terminazione dei cosidetti loop lineari deterministici. In questo contesto la mia ricerca si occupa di
  investigare il ruolo e le proprietà di una particolare classe di funzioni, le
  \textbf{multiphase linear ranking functions}, che si sono dimostrate essere un
  valido strumento per la dimostrazione della terminazione dei suddetti loop (
  si vedano definizioni seguenti). La mia ricerca è orientata all'investigazione di
  problemi teorici riguardanti:
  \begin{itemize}
    \item L'esistenza di un algoritmo (assieme a soundness e completeness) per
    la sintetizzazione di questo tipo di ranking function sia sui razionali che sugli interi.
    \item L'esistenza di un bound di qualche tipo sul numero di componenti.
    \item Individuazione di sottoclassi di SLC che hanno una RF di questo tipo.
    \end{itemize}
    
  

\begin{mydef}
Un single path linear constraint loop  su $n$ variabili $x_1 \ldots x_n$ \`e
della forma

\[
while (Bx \leq b); \:\: do \: \;A \begin{pmatrix}x\\x'\end{pmatrix} \leq c
\] 
dove $B \in \mathbb{Q}^{m \times n}$, $x,x' \in \mathbb{Q}^n$, $b \in
\mathbb{Q}^n$, $A \in \mathbb{Q}^{p \times n}$ e $c \in
\mathbb{Q}^p$. \\ $(Bx \leq b)$ e $A \begin{pmatrix}x\\x'\end{pmatrix} \leq c$
sono chiamati rispettivamente \textbf{guard} e \textbf{update} del loop.
Quest'ultimo è \textbf{deterministico} se pu\`o essere riscritto come un sistema
di uguaglianze ($A \begin{pmatrix}x\\x'\end{pmatrix} = c$).
Il vettore $\begin{pmatrix}x\\x'\end{pmatrix} \in \mathbb{Q}^{2n}$ vive nello
spazio delle transizioni del loop. Pi\`u formalmente 
$\begin{pmatrix}x\\x'\end{pmatrix}$ è una transizione se $x$  soddisfa il guard 
e $x'$ l' update.
\end{mydef}

\subsubsection{Multiphase ranking function - MPhiRF}

Consideriamo un SLC Q. Una tupla \(<\rho_1,...,\rho_d>\) è una MPHiRF
se per ogni transizione \(\begin{pmatrix}x\\x'\end{pmatrix} \in Q\), \(\exists i \in [1..d]\) tale che:
\begin{enumerate}
\item $\begin{aligned}[t]
    \rho_j(x)-\rho_j(x') \geq 1, \;\;\forall j \leq i\\
\end{aligned}$
\item $\begin{aligned}[t]
    \rho_i(x) \geq 0\\
\end{aligned}$
\item $\begin{aligned}[t]
    \rho_j(x)< 0,  \;\;\forall j<i\\
\end{aligned}$
\end{enumerate}

Intuitivamente esiste una funzione $\rho_1(x)$ che è sempre
decrescente in  Q e quando diventa negativa $\rho_2(x)$ inizia a decrescere,
e quando anch'essa diventa negativa ne esiste un altra che decresce nella stessa
maniera e così via.

Ovviamente tutto ciò \textbf{implica la terminazione del loop}.

Il punto (1) significa che quando una componente inizia a decrescere, lo farà
per sempre.
I punti (2,3) significano che se usiamo la $i$-esima componente per il ranking
di $\begin{pmatrix}x\\x'\end{pmatrix}$, allora tutte le componenti $j<i$ sono
già negative, altrimenti ne avremmo usata una tra quelle per effettuare il ranking di $\begin{pmatrix}x\\x'\end{pmatrix}$
-- perchè sono anch'esse decrescenti.
Si noti come (3) è in qualche modo ridondante perchè avremmo potuto definire la
stessa classe di funzioni prendendo il più piccolo indice $i$ tale che (1,2)
fossero verificati.

Come esempio, consideriamo il seguente loop:
    \[while ( x>0 )\: { x'=x+y, y'=y-1 }\]

che ha MPhiRF: \(<y,x>.\)
Tutte le transizioni del tipo $(x,y\geq 0)$ hanno come ranking function
$\rho_1(x)=y$ che è positiva e decrescente $(y-(y-1)) =1 \geq 1$. Quando essa
diventa negative --per le transizioni del tipo $(x,y<0)$--, allora
$\rho_2(x)=x$ è positiva e decrescente $(x - (x-y)) = y \geq 1$.



\end{document}
