\chapter{Introduction}


Over the last two decades, lot has changed regarding the way modern scientific applications are designed, written and executed especially in the field of data-analytics, scientific computing and visualization. The main reasons behind these changes are that the size of the problems that scientists try to tackle nowadays are much bigger and because of the amount of available raw data that can be analyzed has widened the spectrum of applications of computing. Data Analytics and Big Data techniques are applied in pretty much every field of science and have been exploited effectively also by governments and corporate organizations.

Traditionally performance improvements in computer architecture have come from cramming more functional units onto silicon, increasing clock speeds and transistors number. Coupled with increasing clock speeds, CPU performance has until recently doubled every two years.  But it is important to acknowledge that this trend cannot be sustained indefinitely or forever. Increased clock speed and transistor number require more power and consequently generate more heat, at the point that the heat emitted from the modern processor, measured in power density rivals the heat of a nuclear reactor core!
But the power demand did not stop in over the years and is not going to stop in the near future,  and from these reasons comes the necessity of relying heavily on parallel architectures. Multicore (2,4,8,12, up to 40) CPUs  are ubiquitous at the point that even smart-phones are proper multi-core machines. Dedicated computing machines are nowadays large, powerful agglomerate of multi-core computing nodes interconnected via a network. Those kind of parallel machines are complex and their efficient programming is hard, bug-prone and time-consuming. 

In the field of scientific computing, and of modeling and simulation especially, parallel machines are used to obtain an approximate numerical solution to differential equations which describe physical system rigorously, as for example for the \textit{Maxwell's} equations at the foundation of classical electromagnetism or the \textit{Navier-Stokes} for fluid dynamics.
The classical approach, based on calculus often fails to solve these kinds of equations analytically, making computer-based numerical approach absolutely necessary.
Approximate numerical solution of partial differential equation can be obtained by applying a number of methods, as the finite element or finite difference method which yields approximate values of the unknowns at a discrete number of points over the domain.
When large domains are considered, large parallel machines are required in order to process the resulting huge amount of mesh nodes. Parallel programming is notoriously complex often requiring great programming effort in order to obtain efficient solvers targeting large computing cluster. This is especially true since heterogeneous hardware and GPGPU has become mainstream.

The main thrust of this work is the creation of a programming abstraction and a runtime library for seamless implementation of numerical methods on regular grids targeting different computer architecture: from commodity single-core laptop to large cluster of heterogeneous accelerators. A framework, \texttt{OpenCAL} had been developed, which expose a domain specific language for the definition of a large class of numerical models and their subsequent deployment on the targeted machines. Architecture programming details are abstracted from the programmer that with little or no intervention at all can obtain a \textit{serial, multi-core, single-GPU, multi-GPUs and cluster of GPUs} \texttt{OpenCAL} application. 
Results show that the framework is effective in reducing programmer effort in producing efficient parallel numerical solvers.

The rest of the document is organized as follows:
Chapters \ref{ch:parallel_computing} and  \ref{ch:FDM} introduces the main targeted numerical models, and parallel machines, respectively.
Chapters \ref{ch:opencal} and \ref{ch:opencal_cluster} describe \texttt{OpenCAL}, its implementation, usage and performance on a number of benchmarks.
Chapters \ref{ch:bacteria}, \ref{ch:flocking}, \ref{ch:stream_compaction} introduces some HPC numerical modeling and simulation applications that have been investigated.
In particular, Chapter \ref{ch:bacteria} introduces a specialized framework based on \texttt{OpenCAL} for tracking particle-like objects from time-lapse video which has been applied to analyze the motility  the of \textit{B. subtilis} bacterium.